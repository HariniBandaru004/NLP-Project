{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dataset=pd.read_csv(\"hello.txt\",sep='delimiter',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how are glacier caves formed ?\\tA partly subme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how are glacier caves formed ?\\tThe ice facade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how are glacier caves formed ?\\tIce formations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how are glacier caves formed ?\\tA glacier cave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how are glacier caves formed ?\\tGlacier caves ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   H\n",
       "0  how are glacier caves formed ?\\tA partly subme...\n",
       "1  how are glacier caves formed ?\\tThe ice facade...\n",
       "2  how are glacier caves formed ?\\tIce formations...\n",
       "3  how are glacier caves formed ?\\tA glacier cave...\n",
       "4  how are glacier caves formed ?\\tGlacier caves ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      H\n",
      "0     how are glacier caves formed ?\\tA partly subme...\n",
      "1     how are glacier caves formed ?\\tThe ice facade...\n",
      "2     how are glacier caves formed ?\\tIce formations...\n",
      "3     how are glacier caves formed ?\\tA glacier cave...\n",
      "4     how are glacier caves formed ?\\tGlacier caves ...\n",
      "...                                                 ...\n",
      "5921                 What's the best way to the station\n",
      "5922                      Where is the nearest bus stop\n",
      "5923                         Where is the next bus stop\n",
      "5924                                 You can't miss it.\n",
      "5925                                           See you.\n",
      "\n",
      "[5926 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(n_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n_dataset.H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "class MarkovChain:\n",
    "    def __init__(self):\n",
    "        self.lookup_dict = defaultdict(list)  \n",
    "    \n",
    "    def add_document(self, string):\n",
    "        preprocessed_list = self._preprocess(string)\n",
    "        pairs = self.__generate_tuple_keys(preprocessed_list)\n",
    "        for pair in pairs:\n",
    "            self.lookup_dict[pair[0]].append(pair[1])\n",
    "        pairs2 = self.__generate_2tuple_keys(preprocessed_list)\n",
    "        for pair in pairs2:\n",
    "            self.lookup_dict[tuple([pair[0], pair[1]])].append(pair[2])\n",
    "        pairs3 = self.__generate_3tuple_keys(preprocessed_list)\n",
    "        for pair in pairs3:\n",
    "            self.lookup_dict[tuple([pair[0], pair[1], pair[2]])].append(pair[3])\n",
    "            \n",
    "    def _preprocess(self, string):\n",
    "        cleaned = re.sub(r'\\W+', ' ', string).lower()\n",
    "        tokenized = word_tokenize(cleaned)\n",
    "        return tokenized\n",
    "    \n",
    "    def __generate_tuple_keys(self, data):\n",
    "        if len(data) < 1:\n",
    "            return\n",
    "\n",
    "        for i in range(len(data) - 1):\n",
    "            yield [ data[i], data[i + 1] ]\n",
    "            \n",
    "    def __generate_2tuple_keys(self, data):\n",
    "        if len(data) < 2:\n",
    "            return\n",
    "\n",
    "        for i in range(len(data) - 2):\n",
    "            yield [ data[i], data[i + 1], data[i+2] ]\n",
    "    \n",
    "    \n",
    "    def __generate_3tuple_keys(self, data):\n",
    "        if len(data) < 3:\n",
    "            return\n",
    "\n",
    "        for i in range(len(data) - 3):\n",
    "            yield [ data[i], data[i + 1], data[i+2], data[i+3] ]\n",
    "    \n",
    "    def oneword(self, string):\n",
    "        return Counter(self.lookup_dict[string]).most_common()[:3]\n",
    "\n",
    "    def twowords(self, string):\n",
    "        suggest = Counter(self.lookup_dict[tuple(string)]).most_common()[:3]\n",
    "        if len(suggest)==0:\n",
    "            return self.oneword(string[-1])\n",
    "        return suggest\n",
    "\n",
    "    def threewords(self, string):\n",
    "        suggest = Counter(self.lookup_dict[tuple(string)]).most_common()[:3]\n",
    "        if len(suggest)==0:\n",
    "            return self.twowords(string[-2:])\n",
    "        return suggest\n",
    "    \n",
    "    def morewords(self, string):\n",
    "        return self.threewords(string[-3:])\n",
    "\n",
    "    \n",
    "    def generate_text(self, string):\n",
    "        if len(self.lookup_dict) > 0:\n",
    "            tokens = string.split(\" \")\n",
    "            if len(tokens)==1:\n",
    "                print(\"Next word suggestions:\", self.oneword(string))\n",
    "            elif len(tokens)==2:\n",
    "                print(\"Next word suggestions:\", self.twowords(string.split(\" \")))\n",
    "            elif len(tokens)==3:\n",
    "                print(\"Next word suggestions:\", self.threewords(string.split(\" \")))\n",
    "            elif len(tokens)>3:\n",
    "                print(\"Next word suggestions:\", self.morewords(string.split(\" \")))\n",
    "        return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n_dataset.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will be\n",
      "Next word suggestions: [('the', 3), ('hosted', 2), ('shut', 2)]\n"
     ]
    }
   ],
   "source": [
    "my_markov = MarkovChain()\n",
    "my_markov.add_document(n_dataset.to_string())\n",
    "my_markov.generate_text(input().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
